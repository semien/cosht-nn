{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5_frameworks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz4_lGlZ_A6G",
        "colab_type": "text"
      },
      "source": [
        "# –£—Ä–æ–∫ 6. –í–≤–µ–¥–µ–Ω–∏–µ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: TensorFlow, Keras\n",
        "\n",
        "–ù–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —É—Ä–æ–∫–∞—Ö –º—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–æ–Ω—è—Ç–∏—è–º–∏ —Ç–æ–≥–æ, —á—Ç–æ –∏–∑ —Å–µ–±—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏. –ú—ã —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª–∏ –æ–¥–Ω–æ—Å–ª–æ–π–Ω—ã–µ (shallow) –∏ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ (deep) –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (fully connected NN). –û–¥–Ω–∞–∫–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å –Ω—É–ª—è –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è—Ç. –ù–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å –¥–æ—Å—Ç—É–ø–Ω–æ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –±–∏–±–ª–∏–æ—Ç–µ–∫ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏ –ø–æ deep learning. –°—Ä–µ–¥–∏ –Ω–∏—Ö:\n",
        " - Tensorflow (Google);\n",
        " - Theano (University of Montreal);\n",
        " - PyTorch (Facebook);\n",
        " - Caffe (UC Berkeley);\n",
        " - MXNet (Apache);\n",
        " - CNTK (Microsoft).\n",
        " \n",
        "–í—Å–µ —ç—Ç–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–º–µ—é—Ç –ø–æ–¥–¥–µ—Ä–∂–∫—É CUDA, —Ç–æ –µ—Å—Ç—å –º–æ–∂–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞—Ö nvidia. –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —ç—Ç–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞ –ø–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å—É, –æ–¥–Ω–∞–∫–æ —Å—É—Ç—å –≤–µ–∑–¥–µ —Ç–∞ –∂–µ —Å–∞–º–∞—è: –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—é—Ç —à–∞–≥ forward –∏ backward propagation –∏ –æ—Å—É—â–µ—Å—Ç–≤–ª—è—é—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è —Å –∑–∞–¥–∞–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π –æ—à–∏–±–∫–∏ –∏ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–≤ —Ç.—á. –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–º).\n",
        "\n",
        "## Keras\n",
        "\n",
        "$\\textbf{Keras}$ —Ç–æ–∂–µ —á–∞—Å—Ç–æ –Ω–∞–∑—ã–≤–∞—é—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ–¥–Ω–∞–∫–æ —ç—Ç–æ –Ω–µ–≤–µ—Ä–Ω–æ. Keras - —ç—Ç–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å, —É–ø—Ä–æ—â–∞—é—â–∏–π –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏ –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (Keras –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç TensorFlow, Theano –∏ CNTK). –ï–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ–π –∏ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–π, –≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ —á–µ–≥–æ –æ–Ω —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ_BQj5nDapS",
        "colab_type": "text"
      },
      "source": [
        "## –ü—Ä–∏–º–µ—Ä –∑–∞–¥–∞—á –Ω–∞ TensorFlow\n",
        "\n",
        "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏ MSE\n",
        "\n",
        "$$loss = \\mathcal{L}(\\hat{y}, y) = (\\hat y^{(i)} - y^{(i)})^2: \\tag{1}$$\n",
        "\n",
        "```python\n",
        "y_hat = tf.constant(36, name='y_hat')            # Define y_hat constant. Set to 36.\n",
        "y = tf.constant(39, name='y')                    # Define y. Set to 39\n",
        "\n",
        "loss = tf.Variable((y - y_hat)**2, name='loss')  # Create a variable for the loss\n",
        "\n",
        "init = tf.global_variables_initializer()         # When init is run later (session.run(init)),\n",
        "                                                 # the loss variable will be initialized and ready to be computed\n",
        "with tf.Session() as session:                    # Create a session and print the output\n",
        "    session.run(init)                            # Initializes the variables\n",
        "    print(session.run(loss))                     # Prints the loss\n",
        "\n",
        "```\n",
        "\n",
        "–õ–æ–≥–∏–∫–∞ TensorFlow –≤ —Å–ª–µ–¥—É—é—â–µ–º: —Å–Ω–∞—á–∞–ª–∞ –º—ã –æ–ø–∏—Å—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –Ω–∏–∫–∞–∫–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç. –î–∞–ª–µ–µ –º—ã –¥–æ–ª–∂–Ω—ã –Ω–∞—á–∞—Ç—å —Ç.–Ω. \"—Å–µ—Å—Å–∏—é\" (session): –≤–æ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏ –±—É–¥—É—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –æ–ø–∏—Å–∞–Ω–Ω—ã–µ –Ω–∞–º–∏ —Ä–∞–Ω–µ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVPPYvItJ0At",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 1. –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ $y = (w-5)^2$ –ø–æ $w$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFahnvEgDMGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_2D-FFiD-wB",
        "colab_type": "code",
        "outputId": "bbdc4b8e-ca19-4bbc-d548-75fc7355a35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "w = tf.Variable(0,dtype = tf.float32)\n",
        "cost = tf.add(tf.add(w**2, tf.multiply(-10.,w)), 25)\n",
        "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "print(session.run(w))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 13:41:59.077844 139668220368768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Wjh_hADQP1",
        "colab_type": "code",
        "outputId": "05f47d62-03d6-4c84-d772-e9a253a26c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "session.run(train)\n",
        "print(session.run(w))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.099999994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyzSMi8JJRbe",
        "colab_type": "code",
        "outputId": "a828b5b2-5e61-4326-a29f-720e3c937da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(100):\n",
        "  session.run(train)\n",
        "  print(session.run(w))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.198\n",
            "0.29404\n",
            "0.3881592\n",
            "0.480396\n",
            "0.5707881\n",
            "0.6593723\n",
            "0.7461849\n",
            "0.83126116\n",
            "0.91463596\n",
            "0.99634326\n",
            "1.0764164\n",
            "1.154888\n",
            "1.2317903\n",
            "1.3071545\n",
            "1.3810115\n",
            "1.4533913\n",
            "1.5243235\n",
            "1.593837\n",
            "1.6619602\n",
            "1.728721\n",
            "1.7941467\n",
            "1.8582637\n",
            "1.9210985\n",
            "1.9826765\n",
            "2.0430229\n",
            "2.1021624\n",
            "2.160119\n",
            "2.2169166\n",
            "2.2725782\n",
            "2.3271267\n",
            "2.3805842\n",
            "2.4329727\n",
            "2.4843132\n",
            "2.534627\n",
            "2.5839343\n",
            "2.6322556\n",
            "2.6796105\n",
            "2.7260182\n",
            "2.7714977\n",
            "2.8160677\n",
            "2.8597465\n",
            "2.9025514\n",
            "2.9445004\n",
            "2.9856105\n",
            "3.0258982\n",
            "3.0653803\n",
            "3.1040728\n",
            "3.1419914\n",
            "3.1791515\n",
            "3.2155685\n",
            "3.2512572\n",
            "3.286232\n",
            "3.3205073\n",
            "3.3540971\n",
            "3.387015\n",
            "3.4192748\n",
            "3.4508893\n",
            "3.4818716\n",
            "3.5122342\n",
            "3.5419896\n",
            "3.5711498\n",
            "3.599727\n",
            "3.6277323\n",
            "3.6551776\n",
            "3.682074\n",
            "3.7084327\n",
            "3.7342641\n",
            "3.759579\n",
            "3.7843874\n",
            "3.8086996\n",
            "3.8325257\n",
            "3.8558753\n",
            "3.8787577\n",
            "3.9011827\n",
            "3.923159\n",
            "3.9446957\n",
            "3.9658017\n",
            "3.9864857\n",
            "4.006756\n",
            "4.026621\n",
            "4.046088\n",
            "4.0651665\n",
            "4.0838633\n",
            "4.102186\n",
            "4.1201425\n",
            "4.1377397\n",
            "4.154985\n",
            "4.171885\n",
            "4.1884475\n",
            "4.2046785\n",
            "4.220585\n",
            "4.236173\n",
            "4.2514496\n",
            "4.2664204\n",
            "4.281092\n",
            "4.29547\n",
            "4.309561\n",
            "4.3233695\n",
            "4.336902\n",
            "4.350164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrGJjXo3KjxN",
        "colab_type": "text"
      },
      "source": [
        "**–ó–∞–º–µ—á–∞–Ω–∏–µ 1.** –ù–∞ –ø—Ä–∏–º–µ—Ä–µ –≤–∏–¥–Ω–æ, —á—Ç–æ —Ç–µ–ø–µ—Ä—å –Ω–∞–º –º–æ–∂–Ω–æ –Ω–µ –∑–∞–±–æ—Ç–∏—Ç—å—Å—è –æ –ø—Ä–æ—Ü–µ–¥—É—Ä–µ –≤–∑—è—Ç–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö - —ç—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—è minimize –∫–ª–∞—Å—Å–∞ GradientDescentOptimizer. –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –Ω–∞–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —à–∞–≥ forward propagation, –∞ backpropagation –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.\n",
        "\n",
        "**–ó–∞–º–µ—á–∞–Ω–∏–µ 2.** –î–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≤–∏—Å–µ–ª–∞ —Ç–æ–ª—å–∫–æ –æ—Ç –æ–¥–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π, –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–π –±—ã–ª–æ –∑–∞—Ä–∞–Ω–µ–µ –∏–∑–≤–µ—Å—Ç–Ω–æ. –û–¥–Ω–∞–∫–æ —Ñ—É–Ω–∫—Ü–∏—è –æ—à–∏–±–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏—Ç –µ—â–µ –∏ –æ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞—Ä–∞–Ω–µ–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã (–Ω–∞ —ç—Ç–∞–ø–µ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏). –ß—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å —Ç–∞–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–≥—Ä—É–±–æ –≥–æ–≤–æ—Ä—è, —Å –≤—Ö–æ–¥–Ω—ã–º –º–∞—Å—Å–∏–≤–æ–º X), –≤ TensorFlow —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "```python\n",
        "tf.placeholder(dtype, shape),\n",
        "```\n",
        "–≥–¥–µ dtype - —ç—Ç–æ —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö (int, float16, float32), –∞ shape - —ç—Ç–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huWIxXXlN0nf",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 2. –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏  $ùë¶=x_0\\cdot w^2 - x_1 \\cdot w + x_2$  –ø–æ  ùë§\n",
        "\n",
        "–ü—É—Å—Ç—å —Ç–µ–ø–µ—Ä—å —Ñ—É–Ω–∫—Ü–∏—è –æ—à–∏–±–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º $w$, –Ω–æ –∏ –¥–∞–Ω–Ω—ã–º—ã $x$. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö tf.placeholder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoq01epMNzw2",
        "colab_type": "code",
        "outputId": "a7bddf06-bf02-46f4-8014-55ab49a52a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "coefficients = np.array([[1.,10.,25.]])\n",
        "\n",
        "w = tf.Variable(0,dtype = tf.float32)\n",
        "x = tf.placeholder(dtype = tf.float32, shape = [1,3])\n",
        "cost = x[0][0] * w**2 - x[0][1] * w + x[0][2]\n",
        "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
        "\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "print(session.run(w))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewH3PsHiJnFX",
        "colab_type": "code",
        "outputId": "e5008976-b27e-4c94-bb74-3d6b1a5c4fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i in range(1000):\n",
        "  session.run(train, feed_dict = {x:coefficients})\n",
        "print(session.run(w))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.999988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ASaBVlSGIP",
        "colab_type": "text"
      },
      "source": [
        "–ù–∞–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º –Ω–∞ TensorFlow –º–æ–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —à–∞–≥–∞–º–∏:\n",
        "\n",
        "1. –û–±—ä—è–≤–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ Tensors (variables), –Ω–∞–¥ –∫–æ—Ç–æ—Ä—ã–º–∏ –Ω–∏–∫–∞–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å–æ–≤–µ—Ä—à–µ–Ω–æ –ø–æ–∫–∞ –Ω–µ –±—É–¥–µ—Ç. \n",
        "2. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É —ç—Ç–∏–º–∏ Tensors.\n",
        "3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—åTensors. \n",
        "4. –°–æ–∑–¥–∞—Ç—å —Å–µ—Å—Å–∏—é. \n",
        "5. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Å—Å–∏—é, –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∫–æ—Ç–æ—Ä–æ–π –±—É–¥—É—Ç –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –≤—ã—à–µ–æ–ø–∏—Å–∞–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞–¥ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ Tensors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XST9RIFiVyRg",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 3. –ß—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ –Ω–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å Session?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5SNcwtaP9vK",
        "colab_type": "code",
        "outputId": "1bdead15-cb6a-4936-cdbc-f2634a0aee02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tf.constant(2)\n",
        "b = tf.constant(10)\n",
        "c = tf.multiply(a,b)\n",
        "print(c)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Mul_3:0\", shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnvW73jdV8bk",
        "colab_type": "code",
        "outputId": "4d2da1b4-68e8-4469-a6d4-06694426424d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "print(sess.run(c))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lru9Ir1IwTtV",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 4.  One-hot Encoding. –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ —Ñ—É–Ω–∫—Ü–∏—è softmax\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1J0WflUO8DxWyQuHxcOQYBE1GhfEyOdeE\" style=\"width:665px;height:320px;\">\n",
        "\n",
        "–ü—É—Å—Ç—å –ø–µ—Ä–µ–¥ –Ω–∞–º–∏ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞–º –Ω–∞–¥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ü–≤–µ—Ç —Å–≤–µ—Ç–æ—Ñ–æ—Ä–∞ –ø–æ –∫–∞–∫–∏–º-—Ç–æ –≤—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º. –¢–æ–≥–¥–∞ –∫–ª–∞—Å—Å–æ–≤ –±—É–¥–µ—Ç —Ç—Ä–∏: [–∫—Ä–∞—Å–Ω—ã–π, –∂–µ–ª—Ç—ã–π, –∑–µ–ª–µ–Ω—ã–π]. –ú—ã —É–∂–µ –Ω–µ –º–æ–∂–µ–º –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º —á–∏—Å–ª–æ–º –Ω–∞ –≤—ã—Ö–æ–¥–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ, —á—Ç–æ–±—ã –Ω–µ–π—Ä–æ—Å–µ—Ç—å –≤—ã–¥–∞–≤–∞–ª–∞ –≤—ã—Ö–æ–¥ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 3 (3 –≤ –¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ). –¢–æ–≥–¥–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∫–∞–∂–¥—ã–π —Ü–≤–µ—Ç —Å–≤–µ—Ç–æ—Ñ–æ—Ä–∞ —Ç–æ–∂–µ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–º. –ü—Ä–æ—Å—Ç–µ–π—à–∏–π —Å–ø–æ—Å–æ–± —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å - one-hot encoding. –¢–æ–≥–¥–∞:\n",
        " - –∫—Ä–∞—Å–Ω—ã–π = $(1, 0, 0)^T$;\n",
        " - –∂–µ–ª—Ç—ã–π = $(0,1,0)^T$;\n",
        " - –∑–µ–ª–µ–Ω—ã–π = $(0,0,1)^T$.\n",
        " \n",
        "–ù–∞ –≤—ã—Ö–æ–¥–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –±—É–¥–µ—Ç —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä, i-—É—é –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É –∫–æ—Ç–æ—Ä–æ–≥–æ –º–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ –∫ i-–æ–º—É –∫–ª–∞—Å—Å—É. \n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å:\n",
        "\n",
        "$$J(y, \\hat y) = -\\frac{1}{N} \\sum_{s\\in S} \\sum_{c \\in C} 1_{s\\in c} \\log {p(s \\in c)}.$$\n",
        "\n",
        "–°—É–º–º–∞ –≤—Å–µ—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–æ–ª–∂–Ω–∞ —Ä–∞–≤–Ω—è—Ç—å—Å—è –µ–¥–∏–Ω–∏—Ü–µ:\n",
        "\n",
        "$$\\forall l \\in[1,N]  \\quad\\sum_{i=1}^m y_i^{(l)} = 1,$$\n",
        "\n",
        "–≥–¥–µ N -–∫–æ–ª-–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤, l -–∫–æ–ª-–≤–æ –∫–ª–∞—Å—Å–æ–≤. –ß—Ç–æ–±—ã —Ç–∞–∫–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–ª–æ—Å—å, –≤–≤–æ–¥–∏—Ç—Å—è –Ω–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è $\\textit{Softmax}:$\n",
        "\n",
        "$$Softmax(z)_i = \\frac{\\exp{(z_i)}}{\\sum_{j=1}^m \\exp{(z_j)}}, \\quad i \\in [1,m]. $$\n",
        "\n",
        "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã —Å—É–º–º–∞ –≤—Å–µ—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Ä–∞–≤–Ω—è–ª–∞—Å—å –µ–¥–∏–Ω–∏—Ü–µ, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è (—Ä–∞–≤–Ω–æ –∫–∞–∫ –∏ —Ç–æ, —á—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å - —ç—Ç–æ –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞).\n",
        "\n",
        "–í TensorFlow –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ y –≤ one-hot –≤–µ–∫—Ç–æ—Ä—ã:\n",
        "\n",
        "- tf.one_hot(labels, depth, axis)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSHj-iPo2dh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_matrix(labels, C):\n",
        "    \"\"\"\n",
        "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
        "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
        "                     will be 1. \n",
        "                     \n",
        "    Arguments:\n",
        "    labels -- vector containing the labels \n",
        "    C -- number of classes, the depth of the one hot dimension\n",
        "    \n",
        "    Returns: \n",
        "    one_hot -- one hot matrix\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create a tf.constant equal to C (depth), name it 'C'.\n",
        "    C = tf.constant(C, name = 'C')\n",
        "    \n",
        "    # Use tf.one_hot, be careful with the axis\n",
        "    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n",
        "    \n",
        "    # Create the session\n",
        "    sess = tf.Session()\n",
        "    \n",
        "    # Run the session\n",
        "    one_hot = sess.run(one_hot_matrix)\n",
        "    \n",
        "    # Close the session\n",
        "    sess.close()\n",
        "    \n",
        "    \n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS_f40y22eT8",
        "colab_type": "code",
        "outputId": "36eebc29-03ef-4e0b-c462-c62a7d7cf166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "labels = np.array([1,2,3,0,2,1])\n",
        "one_hot = one_hot_matrix(labels, C = 4)\n",
        "print (\"one_hot = \" + str(one_hot))\n",
        "print(type(one_hot))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT9WDx1i6uCn",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 5. tf.layers\n",
        "\n",
        "–í TensorFlow –º–æ–∂–Ω–æ –ª–∏–±–æ –ø—Ä–æ–ø–∏—Å—ã–≤–∞—Ç—å —Å–∞–º–æ–º—É —Ü–µ–ø–æ—á–∫—É –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–∏—Ö –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ, –ª–∏–±–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≥–æ—Ç–æ–≤–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ tf.layers. –ú—ã –ø–æ–∫–∞ –∑–Ω–∞–∫–æ–º—ã —Ç–æ–ª—å–∫–æ —Å –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–º–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏ (fully connected NN), –∏—Ö —Å–ª–æ–∏ –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è Dense layers. –ü—Ä–∏–º–µ—Ä –≤–Ω–∏–∑—É –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–∞–∫–æ–π —Å–ª–æ–π (–±–µ–∑ —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è!):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Wck8-n7CbU",
        "colab_type": "code",
        "outputId": "7decce1a-8c79-4a45-d929-8b28837fe4c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "y = tf.layers.dense(x, units=1, kernel_initializer=tf.zeros_initializer())\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0723 08:13:59.179983 140057250158464 deprecation.py:323] From <ipython-input-11-7d9f41f4ec6c>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm82Jk8Y7tRE",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 6. –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
        "\n",
        "–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è - —ç—Ç–æ –∑–∞–¥–∞—á–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∑–∞–∫–ª—é—á–∞—é—â–∞—è—Å—è –≤ –ª–∏–Ω–µ–π–Ω–æ–π –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π y:\n",
        "\n",
        "$$ y = Wx + b, \\quad J = \\sum(\\hat y_i - y_i)^2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnbkNFbY7uHp",
        "colab_type": "code",
        "outputId": "c09d824b-4662-4343-af6d-e3e4f1dac470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\n",
        "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)\n",
        "\n",
        "linear_model = tf.layers.Dense(units=1)\n",
        "\n",
        "y_pred = linear_model(x)\n",
        "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "for i in range(1000):\n",
        "  _, loss_value = sess.run((train, loss))\n",
        "  #print(loss_value)\n",
        "\n",
        "print(sess.run(y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0723 08:14:00.157789 140057250158464 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-0.04734534]\n",
            " [-1.0229421 ]\n",
            " [-1.9985389 ]\n",
            " [-2.9741354 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXPnEJ2SWr5v",
        "colab_type": "text"
      },
      "source": [
        "### –ó–∞–¥–∞–Ω–∏–µ 1. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ª–∏–Ω–µ–π–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏  $y = W \\cdot x + b$\n",
        "\n",
        "–ü–µ—Ä–≤—ã–º –∑–∞–¥–∞–Ω–∏–µ–º –±—É–¥–µ—Ç –ø–æ–¥—Å—á–µ—Ç —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è: $Y = WX + b$, –≥–¥–µ $W$–∏  $X$ - —ç—Ç–æ —Å–ª—É—á–∞–π–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã, –∞ b - —Å–ª—É—á–∞–π–Ω—ã–π –≤–µ–∫—Ç–æ—Ä. \n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ**: –†–∞—Å—Å—á–∏—Ç–∞—Ç—å $W\\cdot x + b$, –≥–¥–µ $W, x $, –∏ $b$ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. W –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä (4, 3), x - (3,1), b - (4,1). –í –∫–∞—á-–≤–µ –ø—Ä–∏–º–µ—Ä–∞ –ø–æ–∫–∞–∑–∞–Ω–æ, –∫–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ X —Å —Ä–∞–∑–º–µ—Ä–æ–º (3,1):\n",
        "```python\n",
        "X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
        "\n",
        "```\n",
        "–¢–∞–∫–∂–µ –æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏: \n",
        "- tf.matmul(..., ...) - –ø–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü;\n",
        "- tf.add(..., ...) - —Å–ª–æ–∂–µ–Ω–∏–µ –¥–≤—É—Ö –æ–±—ä–µ–∫—Ç–æ–≤;\n",
        "- np.random.randn(...) - –º–µ—Ç–æ–¥ numpy –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–∞—Å—Å–∏–≤–æ–≤ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.\n",
        "\n",
        "**NB** –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∞—Ä–≥—É–º–µ–Ω—Ç name —Ñ—É–Ω–∫—Ü–∏–∏ tf.constant. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –µ–≥–æ —Ç–æ–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É–∫–∞–∑–∞—Ç—å."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv4pXof4XKGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_function():\n",
        "    \"\"\"\n",
        "    Implements a linear function: \n",
        "            Initializes W to be a random tensor of shape (4,3)\n",
        "            Initializes X to be a random tensor of shape (3,1)\n",
        "            Initializes b to be a random tensor of shape (4,1)\n",
        "    Returns: \n",
        "    result -- runs the session for Y = WX + b \n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(1)\n",
        "    \n",
        "    ### START CODE HERE ### (4 lines of code)\n",
        "    X = tf.constant(np.random.randn(3,1), name='X')\n",
        "    W = tf.constant(np.random.randn(4,3), name='W')\n",
        "    b = tf.constant(np.random.randn(4,1), name='b')\n",
        "    Y = tf.add(tf.matmul(W,X), b)\n",
        "    ### END CODE HERE ### \n",
        "    \n",
        "    # Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    sess = tf.Session()\n",
        "    result = sess.run(Y)\n",
        "    ### END CODE HERE ### \n",
        "    \n",
        "    # close the session \n",
        "    sess.close()\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYq395FOGn_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b68a364a-5ec8-439b-c529-98b1ddc78f15"
      },
      "source": [
        "linear_function()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.15657382],\n",
              "       [ 2.95891446],\n",
              "       [-1.08926781],\n",
              "       [-0.84538042]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux5tNrrOZt6w",
        "colab_type": "text"
      },
      "source": [
        "### –ó–∞–¥–∞–Ω–∏–µ 2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (—Å–∏–≥–º–æ–∏–¥—ã)\n",
        "\n",
        "–ò—Ç–∞–∫, –º—ã —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª–∏ —Å–≤–µ—Ä—Ö—É –ª–∏–Ω–µ–π–Ω—É—é —á–∞—Å—Ç—å —à–∞–≥–∞ forward_propagation. Tensorflow —É–∂–µ –∏–º–µ–µ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–∞–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∫–∞–∫ —Å–∏–≥–º–æ–∏–¥–∞ –∏–ª–∏ ReLU. –í –¥–∞–Ω–Ω–æ–º –∑–∞–¥–∞–Ω–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —à–∞–≥ –ø–æ–¥—Å—á–µ—Ç–∞ —Å–∏–≥–º–æ–∏–¥—ã. \n",
        "\n",
        "–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –Ω–∞–¥–æ –±—É–¥–µ—Ç –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–∏–ø–æ–º tf.placeholder. –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Å—Å–∏–∏ –Ω–∞–¥–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å feed_dict —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º z (—Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏).\n",
        "–ü–æ—Ä—è–¥–æ–∫ –±—É–¥–µ—Ç —Å–ª–µ–¥—É—é—â–∏–º:\n",
        " - —Å–æ–∑–¥–∞—Ç—å placeholder x;\n",
        " - –∑–∞–ø–∏—Å–∞—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–¥ –Ω–∏–º –±—É–¥—É—Ç –ø—Ä–æ–≤–æ–¥–∏—Ç—å—Å—è (tf.sigmoid);\n",
        " - –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Å—Å–∏—é.\n",
        "\n",
        "–°–µ—Å—Å–∏—é –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–≤—É–º—è —Å–ø–æ—Å–æ–±–∞–º–∏: \n",
        "\n",
        "**–°–ø–æ—Å–æ–± 1:**\n",
        "```python\n",
        "sess = tf.Session()\n",
        "# –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —à–∞–≥–∏\n",
        "result = sess.run(..., feed_dict = {...})\n",
        "sess.close() # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏\n",
        "```\n",
        "** –°–ø–æ—Å–æ–± 2:**\n",
        "```python\n",
        "with tf.Session() as sess: \n",
        "    # –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —à–∞–≥–∏\n",
        "    result = sess.run(..., feed_dict = {...})\n",
        "    # –ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —è–≤–Ω–æ –∑–∞–∫—Ä—ã–≤–∞—Ç—å —Å–µ—Å—Å–∏—é :)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo89bUribRt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Computes the sigmoid of z\n",
        "    \n",
        "    Arguments:\n",
        "    z -- input value, scalar or vector\n",
        "    \n",
        "    Returns: \n",
        "    results -- the sigmoid of z\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Create a placeholder for x. Name it 'x'.\n",
        "    x = tf.placeholder(dtype = tf.float32, name='x')\n",
        "\n",
        "    # compute sigmoid(x)\n",
        "    sigmoid = tf.sigmoid(x)\n",
        "\n",
        "    # Create a session, and run it.\n",
        "    # You should use a feed_dict to pass z's value to x. \n",
        "    sess = tf.Session()\n",
        "    \n",
        "    # Run session and call the output \"result\"\n",
        "    result = sess.run(sigmoid, feed_dict={x:z})\n",
        "    \n",
        "    sess.close()\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDdNeoQWIohf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe46f318-7e60-44aa-fbd6-fef340ddcfad"
      },
      "source": [
        "sigmoid([[0],[0]])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5],\n",
              "       [0.5]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXS-R_dGcKn7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ summary** \n",
        "\n",
        "–ù–∞ –¥–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ –º—ã —É–∑–Ω–∞–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö –≤–µ—â–µ–π...\n",
        "  \n",
        "1. –ú—ã —É–∑–Ω–∞–ª–∏, —á—Ç–æ —Ç–∞–∫–æ–µ tf.Variable –∏ —á—Ç–æ —Ç–∞–∫–æ–µ tf.placeholder.\n",
        "2. –ù–∞—É—á–∏–ª–∏—Å—å –æ–±—ä—è–≤–ª—è—Ç—å –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏.\n",
        "3. –ù–∞—É—á–∏–ª–∏—Å—å —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–µ—Å—Å–∏—é.\n",
        "4. –ù–∞—É—á–∏–ª–∏—Å—å –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å —Å–µ—Å—Å–∏—é —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º feed_dict - —Å–ª–æ–≤–∞—Ä—è –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lMAiAzndK9U",
        "colab_type": "text"
      },
      "source": [
        "### –ó–∞–¥–∞–Ω–∏–µ 3 -  –ü–æ–¥—Å—á–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏\n",
        "\n",
        "–ú–Ω–æ–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏ —Ç–∞–∫–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ TensorFlow, –≤ —Ç–æ–º —á–∏—Å–ª–µ –±–∏–Ω–∞—Ä–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è: \n",
        "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large ).\\small\\tag{2}$$\n",
        "\n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ**: –†–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–æ–¥—Å—á–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏, –∏—Å–ø–æ–ª—å–∑—É—è —Å–ª–µ–¥—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é: \n",
        "\n",
        "\n",
        "- `tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)`\n",
        "\n",
        "–®–∞–≥–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–µ–¥—É—é—â–∏–º–∏: –ø–æ–¥–∞—Ç—å —Å–∏–≥–º–æ–∏–¥–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ z, –ø–æ—Å—á–∏—Ç–∞—Ç—å —Å–∏–≥–º–æ–∏–¥—É, –∑–∞—Ç–µ–º –≤—ã–∑–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –æ—à–∏–±–∫–∏, –≥–¥–µ logits - —ç—Ç–æ –≤—ã–≤–æ–¥ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å–∏–≥–º–æ–∏–¥—ã, labels - –∏—Å—Ç–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –±—É–¥–µ—Ç –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å—Å—è –ø–æ–¥—Å—á–µ—Ç —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è:\n",
        "\n",
        "$$- \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log \\sigma(z^{[2](i)}) + (1-y^{(i)})\\log (1-\\sigma(z^{[2](i)})\\large )\\small\\tag{2}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwmsy19zb7PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost(logits, labels):\n",
        "    \"\"\"\n",
        "¬†¬†¬†¬†Computes the cost using the sigmoid cross entropy\n",
        "¬†¬†¬†¬†\n",
        "¬†¬†¬†¬†Arguments:\n",
        "¬†¬†¬†¬†logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n",
        "¬†¬†¬†¬†labels -- vector of labels y (1 or 0) \n",
        "    \n",
        "    Note: What we've been calling \"z\" and \"y\" in this class are respectively called \"logits\" and \"labels\" \n",
        "    in the TensorFlow documentation. So logits will feed into z, and labels into y. \n",
        "¬†¬†¬†¬†\n",
        "¬†¬†¬†¬†Returns:\n",
        "¬†¬†¬†¬†cost -- runs the session of the cost (formula (2))\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### \n",
        "    \n",
        "    # Create the placeholders for \"logits\" (z) and \"labels\" (y)\n",
        "    z = tf.placeholder(dtype=tf.float32, name='z')\n",
        "    y = tf.placeholder(dtype=tf.float32, name='y')\n",
        "    \n",
        "    # Use the loss function \n",
        "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z,labels=y)\n",
        "    \n",
        "    # Create a session (approx. 1 line). See method 1 above.\n",
        "    sess = tf.Session()\n",
        "    \n",
        "    # Run the session (approx. 1 line).\n",
        "    cost = sess.run(cost, feed_dict={z:logits, y:labels})\n",
        "    \n",
        "    # Close the session (approx. 1 line). See method 1 above.\n",
        "    sess.close()\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXmCAxs_Lreo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bf13a4e-70f6-453f-bc2f-d7e5a0b0827b"
      },
      "source": [
        "cost([-100,-100],[0,0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n42pi1afqbzh",
        "colab_type": "text"
      },
      "source": [
        "##Keras\n",
        "\n",
        "–ö–∞–∫ —É–∂–µ –±—ã–ª–æ —Å–∫–∞–∑–∞–Ω–æ —Ä–∞–Ω–µ–µ, Keras - —ç—Ç–æ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –æ–±–æ–ª–æ—á–∫–∞ –Ω–∞–¥ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–º –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é Keras –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —è–¥—Ä–æ TensorFlow). –î–∞–ª–µ–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –Ω–∞ Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EVC-cxFq1I0",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 1. –î–≤—É—Å–ª–æ–π–Ω–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:\n",
        " - –≤—Ö–æ–¥ –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (1,100);\n",
        " - –ø–µ—Ä–≤—ã–π —Å–ª–æ–π –∏–º–µ–µ—Ç 32 –Ω–µ–π—Ä–æ–Ω–∞, —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ReLU;\n",
        " - –≤—Ç–æ—Ä–æ–π —Å–ª–æ–π –∏–º–µ–µ—Ç 10 –Ω–µ–π—Ä–æ–Ω–æ–≤, —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ Softmax;\n",
        " - –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è RMSProp;\n",
        " - —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è;\n",
        " - —Ñ—É–Ω–∫—Ü–∏—è –æ—à–∏–±–∫–∏: –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è:\n",
        " $$ \\large CE = - \\large \\sum_i^C y_i \\log(Softmax(z)_i) = - \\large \\log(\\frac{\\exp{(z_i)}}{\\sum_{j=1}^m \\exp{(z_j)}}),$$\n",
        " \n",
        " –≥–¥–µ C -  –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUccb3rr5_fE",
        "colab_type": "code",
        "outputId": "aaa116fc-f3c6-4779-a081-d7524539589d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=100))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate dummy data\n",
        "\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(10, size=(1000, 1))\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "W0723 08:14:01.074979 140057250158464 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0723 08:14:01.076247 140057250158464 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0723 08:14:01.079301 140057250158464 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0723 08:14:01.106580 140057250158464 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0723 08:14:01.125079 140057250158464 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0723 08:14:01.272192 140057250158464 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 277us/step - loss: 2.3494 - acc: 0.1210\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 88us/step - loss: 2.3067 - acc: 0.1340\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 91us/step - loss: 2.2935 - acc: 0.1350\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 83us/step - loss: 2.2816 - acc: 0.1390\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 82us/step - loss: 2.2730 - acc: 0.1600\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 82us/step - loss: 2.2636 - acc: 0.1450\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 80us/step - loss: 2.2511 - acc: 0.1630\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 80us/step - loss: 2.2402 - acc: 0.1740\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 79us/step - loss: 2.2312 - acc: 0.1810\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 79us/step - loss: 2.2217 - acc: 0.2080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f61041a4c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQCbCkN8s-et",
        "colab_type": "text"
      },
      "source": [
        "–®–∞–≥–∏, –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω—ã–µ –≤ Keras –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, –ø–æ—Ö–æ–∂–∏ –Ω–∞ —Ç–µ, —á—Ç–æ –º—ã –ø—Ä–æ–¥–µ–ª—ã–≤–∞–ª–∏ –≤ TensorFlow:\n",
        " \n",
        " - 1) –æ–ø–∏—Å–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ - –æ–±—ä–µ–∫—Ç –∫–ª–∞—Å—Å–∞ Sequential;\n",
        " - 2) –∑–∞–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏ - –º–µ—Ç–æ–¥ compile;\n",
        " - 3) –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ - –º–µ—Ç–æ–¥  fit.\n",
        "–¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Keras –±–æ–ª–µ–µ user-friendly, —á—Ç–æ –Ω–∞–≥–ª—è–¥–Ω–æ –≤–∏–¥–Ω–æ –Ω–∞ –¥–∞–Ω–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ.\n",
        "\n",
        "**–í–∞–∂–Ω–æ–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ** –£ –∫–ª–∞—Å—Å–∞ model –µ—Å—Ç—å –º–µ—Ç–æ–¥ summary, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã–≤–µ—Å—Ç–∏ –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏: –≤ –∫–∞–∫–æ–º —Å–ª–æ–µ —Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ—è –∏ —Ç–¥."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAYBe9YhuA35",
        "colab_type": "code",
        "outputId": "7e3cfc58-6dcd-4b8c-a1b8-a4f7f1caa032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 32)                3232      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,562\n",
            "Trainable params: 3,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVBdS_IpuSo7",
        "colab_type": "text"
      },
      "source": [
        "–í –ø–µ—Ä–≤–æ–º —Å–ª–æ–µ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è 32x100 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ $w_{ij}$ –∏  32 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ $b_j$ - –≤—Å–µ–≥–æ 3232 –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞.\n",
        "\n",
        "–í–æ –≤—Ç–æ—Ä–æ–º —Å–ª–æ–µ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è 10—Ö32 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ $w_{ij}$ –∏ 10 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ $b_j$ - –≤—Å–µ–≥–æ 330 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
        "\n",
        "–î–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç.–Ω. non-trainable parameters (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –Ω—É–∂–Ω–æ –ø–æ–¥–±–∏—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è), –æ–Ω–∏ –±—ã –ø–æ—è–≤–∏–ª–∏—Å—å, –µ—Å–ª–∏ –±—ã –º—ã –¥–æ–±–∞–≤–∏–ª–∏ batch_normalization. \n",
        "\n",
        "–¢–æ–≥–¥–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏–ª—Å—è –±—ã –ø–æ–¥—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ - —Ç–∞–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–∫ —Ä–∞–∑ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ non-trainable parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFSQszs8v8DK",
        "colab_type": "text"
      },
      "source": [
        "###–ü—Ä–∏–º–µ—Ä 2. –ó–∞–¥–∞—á–∞ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ Keras\n",
        "\n",
        "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω –ø—Ä–∏–º–µ—Ä –∑–∞–¥–∞—á–∏, –∫–æ—Ç–æ—Ä—É—é –º—ã —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞–ª–∏ —Å –ø–æ–º–æ—â—å—é —Å—Ä–µ–¥—Å—Ç–≤ numpy - —ç—Ç–æ –∑–∞–¥–∞—á–∞ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–æ—Ç–Ω–µ—Å–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –ª–∏–±–æ –∫ –æ–¥–Ω–æ–º—É, –ª–∏–±–æ –∫ –¥—Ä—É–≥–æ–º—É –∫–ª–∞—Å—Å—É)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV6DZNLawPcw",
        "colab_type": "code",
        "outputId": "f658d4bb-ec6f-41c4-de73-75155d0ae01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Generate dummy data\n",
        "x_train = np.random.random((1000, 20))\n",
        "y_train = np.random.randint(2, size=(1000, 1))\n",
        "x_test = np.random.random((100, 20))\n",
        "y_test = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=20, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128)\n",
        "score = model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0723 08:14:02.409227 140057250158464 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 0s 253us/step - loss: 0.7075 - acc: 0.5340\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 0s 28us/step - loss: 0.7032 - acc: 0.5180\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 0s 27us/step - loss: 0.6971 - acc: 0.5160\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 0s 30us/step - loss: 0.6981 - acc: 0.5220\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 0s 27us/step - loss: 0.6956 - acc: 0.5230\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 0s 27us/step - loss: 0.6984 - acc: 0.5000\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 0s 31us/step - loss: 0.6958 - acc: 0.5210\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 0s 29us/step - loss: 0.6962 - acc: 0.5300\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 0s 28us/step - loss: 0.6912 - acc: 0.5280\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 0s 30us/step - loss: 0.6940 - acc: 0.5200\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 0s 28us/step - loss: 0.6901 - acc: 0.5260\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 0s 26us/step - loss: 0.6887 - acc: 0.5360\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 0s 27us/step - loss: 0.6848 - acc: 0.5410\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 0s 27us/step - loss: 0.6890 - acc: 0.5460\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 0s 26us/step - loss: 0.6912 - acc: 0.5480\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 0s 30us/step - loss: 0.6871 - acc: 0.5470\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 0s 32us/step - loss: 0.6862 - acc: 0.5340\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 0s 36us/step - loss: 0.6886 - acc: 0.5440\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.6860 - acc: 0.5350\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.6896 - acc: 0.5420\n",
            "100/100 [==============================] - 0s 538us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es1NBQZjwgQe",
        "colab_type": "text"
      },
      "source": [
        "**–í–ê–ñ–ù–û** —É –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å —Ç—Ä–∏ –º–µ—Ç–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ —Å–ø—É—Ç–∞—Ç—å –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º:\n",
        " - model.fit(...) - –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –ø—É—Ç–µ–º –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–¥–∞–Ω–Ω–æ–π –æ—à–∏–±–∫–∏ –∑–∞–¥–∞–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º (–Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—é—Ç—Å—è x_train –∏ y_train);\n",
        " - model.evaluate(...) - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–æ–±—É—á–µ–Ω–∏—è –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç) (–Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—é—Ç—Å—è x_test –∏ y_test);\n",
        " - model.predict(...) - –ø–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYekHqBhxgc1",
        "colab_type": "text"
      },
      "source": [
        "### –ó–∞–¥–∞–Ω–∏–µ –Ω–∞ Keras\n",
        "\n",
        "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–∞ Keras –ª—é–±—É—é –∏–∑ —Ä–∞–Ω–µ–µ –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –Ω–∞–º–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π (–º–æ–∂–Ω–æ –¥–∞–∂–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é). –í –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å –∫–æ—Ä–æ–±–æ—á–∫–∞–º–∏ –∏–ª–∏ –Ω–∞–±–æ—Ä —Ç–æ—á–µ–∫ –∏–∑ \"–ª–µ–ø–µ—Å—Ç–∫–æ–≤\".\n",
        "\n",
        "–î–æ–±–∞–≤–∏—Ç—å –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä dropout.\n",
        "\n",
        "–í–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–º adam.\n",
        "\n",
        "**–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ!** –ï—Å–ª–∏ –≤—ã –¥–æ–±–∞–≤–ª—è–µ—Ç–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä, —Ç–æ –Ω–∞–¥–æ —Ä–µ—à–∏—Ç—å, –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –µ–≥–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å. –ß—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –¥–æ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ù–ï –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç activation –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å–ª–æ—è Dense. –ê–∫—Ç–∏–≤–∞—Ü–∏—é –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –Ω–∞–¥–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–∞–∫ —Å–ª–æ–π —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ dropout-a: keras.layers.Activation(activation=—Ñ—É–Ω–∫—Ü–∏—è_–∞–∫—Ç–∏–≤–∞—Ü–∏–∏)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfzeEAGv-qLn",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "PyTorch - –µ—â–µ –æ–¥–∏–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –¥–≤—É—Å–ª–æ–π–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guGm02Rfpq5_",
        "colab_type": "code",
        "outputId": "5a0bb47b-443d-4b15-ef26-395314e79d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out)\n",
        "    \n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y by passing x to the model.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    print(t, loss.item())\n",
        "\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable\n",
        "    # weights of the model). This is because by default, gradients are\n",
        "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 648.992919921875\n",
            "1 631.898193359375\n",
            "2 615.2619018554688\n",
            "3 599.0609741210938\n",
            "4 583.2977905273438\n",
            "5 568.0230712890625\n",
            "6 553.2813110351562\n",
            "7 538.9461669921875\n",
            "8 525.0341186523438\n",
            "9 511.556884765625\n",
            "10 498.5509948730469\n",
            "11 485.9294738769531\n",
            "12 473.6356506347656\n",
            "13 461.6299743652344\n",
            "14 449.9319763183594\n",
            "15 438.528076171875\n",
            "16 427.52752685546875\n",
            "17 416.9284973144531\n",
            "18 406.6570129394531\n",
            "19 396.62274169921875\n",
            "20 386.872802734375\n",
            "21 377.3948974609375\n",
            "22 368.181396484375\n",
            "23 359.2437438964844\n",
            "24 350.5541687011719\n",
            "25 342.0889587402344\n",
            "26 333.8456726074219\n",
            "27 325.7762756347656\n",
            "28 317.9083557128906\n",
            "29 310.25799560546875\n",
            "30 302.7669372558594\n",
            "31 295.4480895996094\n",
            "32 288.3083190917969\n",
            "33 281.3132019042969\n",
            "34 274.4677429199219\n",
            "35 267.7706604003906\n",
            "36 261.2209167480469\n",
            "37 254.81597900390625\n",
            "38 248.55584716796875\n",
            "39 242.4446563720703\n",
            "40 236.47918701171875\n",
            "41 230.63636779785156\n",
            "42 224.92539978027344\n",
            "43 219.3568115234375\n",
            "44 213.90985107421875\n",
            "45 208.5692596435547\n",
            "46 203.33596801757812\n",
            "47 198.2254638671875\n",
            "48 193.2420654296875\n",
            "49 188.35589599609375\n",
            "50 183.56072998046875\n",
            "51 178.84747314453125\n",
            "52 174.2342529296875\n",
            "53 169.7148895263672\n",
            "54 165.28445434570312\n",
            "55 160.95191955566406\n",
            "56 156.71807861328125\n",
            "57 152.5787353515625\n",
            "58 148.53958129882812\n",
            "59 144.5856475830078\n",
            "60 140.7082977294922\n",
            "61 136.91148376464844\n",
            "62 133.2010955810547\n",
            "63 129.57144165039062\n",
            "64 126.02154541015625\n",
            "65 122.54753875732422\n",
            "66 119.14624786376953\n",
            "67 115.81721496582031\n",
            "68 112.55901336669922\n",
            "69 109.37877655029297\n",
            "70 106.28276062011719\n",
            "71 103.2552490234375\n",
            "72 100.2998046875\n",
            "73 97.40912628173828\n",
            "74 94.5858154296875\n",
            "75 91.82258605957031\n",
            "76 89.12432861328125\n",
            "77 86.48992156982422\n",
            "78 83.9086685180664\n",
            "79 81.38993835449219\n",
            "80 78.9322280883789\n",
            "81 76.53439331054688\n",
            "82 74.193115234375\n",
            "83 71.90533447265625\n",
            "84 69.67671203613281\n",
            "85 67.49931335449219\n",
            "86 65.37626647949219\n",
            "87 63.30610656738281\n",
            "88 61.290523529052734\n",
            "89 59.33106231689453\n",
            "90 57.423675537109375\n",
            "91 55.566383361816406\n",
            "92 53.758487701416016\n",
            "93 51.997459411621094\n",
            "94 50.285030364990234\n",
            "95 48.61843490600586\n",
            "96 46.99900436401367\n",
            "97 45.42587661743164\n",
            "98 43.89701461791992\n",
            "99 42.411624908447266\n",
            "100 40.967716217041016\n",
            "101 39.56394958496094\n",
            "102 38.1965446472168\n",
            "103 36.8675422668457\n",
            "104 35.57304000854492\n",
            "105 34.314125061035156\n",
            "106 33.0904426574707\n",
            "107 31.90330696105957\n",
            "108 30.751327514648438\n",
            "109 29.634126663208008\n",
            "110 28.551015853881836\n",
            "111 27.50040054321289\n",
            "112 26.48053550720215\n",
            "113 25.49039649963379\n",
            "114 24.53202247619629\n",
            "115 23.604328155517578\n",
            "116 22.705745697021484\n",
            "117 21.835437774658203\n",
            "118 20.993959426879883\n",
            "119 20.1839656829834\n",
            "120 19.400453567504883\n",
            "121 18.643421173095703\n",
            "122 17.912954330444336\n",
            "123 17.20845603942871\n",
            "124 16.527660369873047\n",
            "125 15.871355056762695\n",
            "126 15.236969947814941\n",
            "127 14.624885559082031\n",
            "128 14.035387992858887\n",
            "129 13.467056274414062\n",
            "130 12.919197082519531\n",
            "131 12.391900062561035\n",
            "132 11.883044242858887\n",
            "133 11.392720222473145\n",
            "134 10.921186447143555\n",
            "135 10.467170715332031\n",
            "136 10.03039264678955\n",
            "137 9.609724998474121\n",
            "138 9.205169677734375\n",
            "139 8.815922737121582\n",
            "140 8.441792488098145\n",
            "141 8.082608222961426\n",
            "142 7.736794948577881\n",
            "143 7.404720783233643\n",
            "144 7.085376262664795\n",
            "145 6.778754711151123\n",
            "146 6.484444618225098\n",
            "147 6.201739311218262\n",
            "148 5.930171489715576\n",
            "149 5.66992712020874\n",
            "150 5.41994047164917\n",
            "151 5.180524826049805\n",
            "152 4.950841426849365\n",
            "153 4.730745315551758\n",
            "154 4.520195484161377\n",
            "155 4.318141937255859\n",
            "156 4.124190807342529\n",
            "157 3.938528299331665\n",
            "158 3.7606558799743652\n",
            "159 3.590407133102417\n",
            "160 3.427407741546631\n",
            "161 3.271199941635132\n",
            "162 3.1217281818389893\n",
            "163 2.9786500930786133\n",
            "164 2.841859817504883\n",
            "165 2.7111055850982666\n",
            "166 2.5860869884490967\n",
            "167 2.466411828994751\n",
            "168 2.352001667022705\n",
            "169 2.2427845001220703\n",
            "170 2.138056755065918\n",
            "171 2.038132905960083\n",
            "172 1.9427076578140259\n",
            "173 1.851449966430664\n",
            "174 1.764272689819336\n",
            "175 1.6810240745544434\n",
            "176 1.6013435125350952\n",
            "177 1.5253599882125854\n",
            "178 1.452742099761963\n",
            "179 1.3834171295166016\n",
            "180 1.3172202110290527\n",
            "181 1.2540292739868164\n",
            "182 1.1938081979751587\n",
            "183 1.1362780332565308\n",
            "184 1.0814073085784912\n",
            "185 1.0290297269821167\n",
            "186 0.9790980219841003\n",
            "187 0.931513786315918\n",
            "188 0.8860119581222534\n",
            "189 0.8426836133003235\n",
            "190 0.8013824820518494\n",
            "191 0.7621361613273621\n",
            "192 0.7246077060699463\n",
            "193 0.6888682246208191\n",
            "194 0.6548169851303101\n",
            "195 0.62237548828125\n",
            "196 0.5914799571037292\n",
            "197 0.5620258450508118\n",
            "198 0.5339679718017578\n",
            "199 0.507253110408783\n",
            "200 0.48183292150497437\n",
            "201 0.4576239585876465\n",
            "202 0.43456169962882996\n",
            "203 0.4125899076461792\n",
            "204 0.39168426394462585\n",
            "205 0.3717900812625885\n",
            "206 0.3528819978237152\n",
            "207 0.3348485231399536\n",
            "208 0.3177132308483124\n",
            "209 0.30139461159706116\n",
            "210 0.285882830619812\n",
            "211 0.27112966775894165\n",
            "212 0.2570958137512207\n",
            "213 0.24378371238708496\n",
            "214 0.2311374694108963\n",
            "215 0.2191101312637329\n",
            "216 0.2076837569475174\n",
            "217 0.19682683050632477\n",
            "218 0.18650846183300018\n",
            "219 0.17669612169265747\n",
            "220 0.167378231883049\n",
            "221 0.1585182398557663\n",
            "222 0.15011118352413177\n",
            "223 0.14213673770427704\n",
            "224 0.13456037640571594\n",
            "225 0.12736345827579498\n",
            "226 0.12051929533481598\n",
            "227 0.1140184998512268\n",
            "228 0.10784883052110672\n",
            "229 0.10199008882045746\n",
            "230 0.09643383324146271\n",
            "231 0.09115587919950485\n",
            "232 0.08615076541900635\n",
            "233 0.08140209317207336\n",
            "234 0.076900415122509\n",
            "235 0.07263479381799698\n",
            "236 0.06859300285577774\n",
            "237 0.064763143658638\n",
            "238 0.06113630533218384\n",
            "239 0.057703807950019836\n",
            "240 0.05444546788930893\n",
            "241 0.051363855600357056\n",
            "242 0.048448510468006134\n",
            "243 0.04568789526820183\n",
            "244 0.04307715594768524\n",
            "245 0.04060637205839157\n",
            "246 0.03827144578099251\n",
            "247 0.03606029972434044\n",
            "248 0.03397204354405403\n",
            "249 0.03199770674109459\n",
            "250 0.03013143688440323\n",
            "251 0.02836821787059307\n",
            "252 0.02670293115079403\n",
            "253 0.025130538269877434\n",
            "254 0.0236462764441967\n",
            "255 0.02224249579012394\n",
            "256 0.020919376984238625\n",
            "257 0.019670380279421806\n",
            "258 0.018492884933948517\n",
            "259 0.01738142967224121\n",
            "260 0.01633339375257492\n",
            "261 0.015345407649874687\n",
            "262 0.014414592646062374\n",
            "263 0.013538156636059284\n",
            "264 0.012712020426988602\n",
            "265 0.011933904141187668\n",
            "266 0.011201111599802971\n",
            "267 0.010511214844882488\n",
            "268 0.009862629696726799\n",
            "269 0.009252178482711315\n",
            "270 0.008677532896399498\n",
            "271 0.008136887103319168\n",
            "272 0.007628594525158405\n",
            "273 0.007150240242481232\n",
            "274 0.006700657308101654\n",
            "275 0.006278058979660273\n",
            "276 0.005880606360733509\n",
            "277 0.005507470574229956\n",
            "278 0.005156636703759432\n",
            "279 0.004827188327908516\n",
            "280 0.004518293775618076\n",
            "281 0.004227309487760067\n",
            "282 0.003954634070396423\n",
            "283 0.0036987299099564552\n",
            "284 0.003458342282101512\n",
            "285 0.0032327768858522177\n",
            "286 0.003021111711859703\n",
            "287 0.0028225502464920282\n",
            "288 0.002636384917423129\n",
            "289 0.0024618441238999367\n",
            "290 0.002298231003805995\n",
            "291 0.0021449788473546505\n",
            "292 0.0020014408510178328\n",
            "293 0.0018669776618480682\n",
            "294 0.001741141895763576\n",
            "295 0.0016234094509854913\n",
            "296 0.0015132382977753878\n",
            "297 0.0014102234272286296\n",
            "298 0.0013138129143044353\n",
            "299 0.0012237363262102008\n",
            "300 0.0011395495384931564\n",
            "301 0.0010608987649902701\n",
            "302 0.0009874292882159352\n",
            "303 0.0009187869727611542\n",
            "304 0.0008547376492060721\n",
            "305 0.0007949327700771391\n",
            "306 0.0007391257677227259\n",
            "307 0.0006871545338071883\n",
            "308 0.0006385857705026865\n",
            "309 0.0005932782078161836\n",
            "310 0.000551100354641676\n",
            "311 0.0005117753171361983\n",
            "312 0.00047514401376247406\n",
            "313 0.0004410176770761609\n",
            "314 0.0004092349554412067\n",
            "315 0.00037964797229506075\n",
            "316 0.0003521117614582181\n",
            "317 0.0003264769911766052\n",
            "318 0.00030264281667768955\n",
            "319 0.0002804660762194544\n",
            "320 0.00025985209504142404\n",
            "321 0.00024069080245681107\n",
            "322 0.000222884671529755\n",
            "323 0.00020634641987271607\n",
            "324 0.00019097251060884446\n",
            "325 0.00017670722445473075\n",
            "326 0.0001634660002309829\n",
            "327 0.00015117452130652964\n",
            "328 0.0001397626765538007\n",
            "329 0.00012918858556076884\n",
            "330 0.00011937754607060924\n",
            "331 0.00011028182052541524\n",
            "332 0.00010185021528741345\n",
            "333 9.404589218320325e-05\n",
            "334 8.680564496899024e-05\n",
            "335 8.010760939214379e-05\n",
            "336 7.39043825888075e-05\n",
            "337 6.816353561589494e-05\n",
            "338 6.284982373472303e-05\n",
            "339 5.7932989875553176e-05\n",
            "340 5.338898336049169e-05\n",
            "341 4.9183603550773114e-05\n",
            "342 4.529772195382975e-05\n",
            "343 4.171014734311029e-05\n",
            "344 3.8391754060285166e-05\n",
            "345 3.532848131726496e-05\n",
            "346 3.250277950428426e-05\n",
            "347 2.9893068131059408e-05\n",
            "348 2.748535007413011e-05\n",
            "349 2.5263767383876257e-05\n",
            "350 2.3214592147269286e-05\n",
            "351 2.1324074623407796e-05\n",
            "352 1.958251050382387e-05\n",
            "353 1.79765593202319e-05\n",
            "354 1.6497820979566313e-05\n",
            "355 1.513681581855053e-05\n",
            "356 1.3883849533158354e-05\n",
            "357 1.2730924936477095e-05\n",
            "358 1.1669661944324616e-05\n",
            "359 1.0693309377529658e-05\n",
            "360 9.796640370041132e-06\n",
            "361 8.970358067017514e-06\n",
            "362 8.212959073716775e-06\n",
            "363 7.516241566918325e-06\n",
            "364 6.876387033116771e-06\n",
            "365 6.287885298661422e-06\n",
            "366 5.748866897192784e-06\n",
            "367 5.254394181974931e-06\n",
            "368 4.80115159007255e-06\n",
            "369 4.385382908367319e-06\n",
            "370 4.004208676633425e-06\n",
            "371 3.6542321595334215e-06\n",
            "372 3.3339774745400064e-06\n",
            "373 3.0406370115088066e-06\n",
            "374 2.7716553177015157e-06\n",
            "375 2.526031721572508e-06\n",
            "376 2.3017553303361638e-06\n",
            "377 2.0965867406630423e-06\n",
            "378 1.9086241991317365e-06\n",
            "379 1.737135676194157e-06\n",
            "380 1.579985564603703e-06\n",
            "381 1.4369302334671374e-06\n",
            "382 1.3060653145657852e-06\n",
            "383 1.1873047469634912e-06\n",
            "384 1.0783826382976258e-06\n",
            "385 9.789144996830146e-07\n",
            "386 8.880361974661355e-07\n",
            "387 8.059918172875769e-07\n",
            "388 7.312341381293663e-07\n",
            "389 6.626366371165204e-07\n",
            "390 6.003597832204832e-07\n",
            "391 5.437086656456813e-07\n",
            "392 4.925770440422639e-07\n",
            "393 4.4564222889675875e-07\n",
            "394 4.0324169958694256e-07\n",
            "395 3.6442406781134196e-07\n",
            "396 3.294227326477994e-07\n",
            "397 2.974109065689845e-07\n",
            "398 2.685645199562714e-07\n",
            "399 2.4242697804766067e-07\n",
            "400 2.1868274302505597e-07\n",
            "401 1.9725473521248205e-07\n",
            "402 1.777247149448158e-07\n",
            "403 1.6020970861063688e-07\n",
            "404 1.4405864590116835e-07\n",
            "405 1.298719638498369e-07\n",
            "406 1.1671597377471699e-07\n",
            "407 1.0495723046233252e-07\n",
            "408 9.420192270681582e-08\n",
            "409 8.476841628635157e-08\n",
            "410 7.607319929547884e-08\n",
            "411 6.819426090487468e-08\n",
            "412 6.118401074672875e-08\n",
            "413 5.490929666507327e-08\n",
            "414 4.9183647377049056e-08\n",
            "415 4.4007730792827715e-08\n",
            "416 3.934905379310294e-08\n",
            "417 3.5186300095801926e-08\n",
            "418 3.148595340007887e-08\n",
            "419 2.8141295516093123e-08\n",
            "420 2.5162311345638955e-08\n",
            "421 2.2467482096999447e-08\n",
            "422 1.996007270577138e-08\n",
            "423 1.7884772773868463e-08\n",
            "424 1.587511810896558e-08\n",
            "425 1.4151294358555333e-08\n",
            "426 1.2614821187639791e-08\n",
            "427 1.1176695124959224e-08\n",
            "428 9.929673083775015e-09\n",
            "429 8.848935806327063e-09\n",
            "430 7.900290199813753e-09\n",
            "431 7.008829516763626e-09\n",
            "432 6.204777580620657e-09\n",
            "433 5.524949830970627e-09\n",
            "434 4.9244546218574214e-09\n",
            "435 4.386172314241321e-09\n",
            "436 3.901296619090999e-09\n",
            "437 3.492443445551885e-09\n",
            "438 3.0738689371645478e-09\n",
            "439 2.72438116510898e-09\n",
            "440 2.44408870919699e-09\n",
            "441 2.180461367018438e-09\n",
            "442 1.9455783650812464e-09\n",
            "443 1.7208665603618556e-09\n",
            "444 1.521557546624308e-09\n",
            "445 1.3721245251119285e-09\n",
            "446 1.2245939817745466e-09\n",
            "447 1.089825008016021e-09\n",
            "448 9.915460674747578e-10\n",
            "449 8.970974518796027e-10\n",
            "450 8.054719113914643e-10\n",
            "451 7.341263708049439e-10\n",
            "452 6.534641716626766e-10\n",
            "453 6.02836947027896e-10\n",
            "454 5.521970658506348e-10\n",
            "455 5.036492889409772e-10\n",
            "456 4.722607305218673e-10\n",
            "457 4.275167442280292e-10\n",
            "458 3.973590900763213e-10\n",
            "459 3.6573677419937667e-10\n",
            "460 3.438125062427133e-10\n",
            "461 3.1300301239767236e-10\n",
            "462 2.917823205272896e-10\n",
            "463 2.7082919240584147e-10\n",
            "464 2.552024980229106e-10\n",
            "465 2.4312898916356573e-10\n",
            "466 2.2621492179464298e-10\n",
            "467 2.167855756018966e-10\n",
            "468 2.0488301333276837e-10\n",
            "469 1.965186763319693e-10\n",
            "470 1.8632063947254807e-10\n",
            "471 1.730940807354031e-10\n",
            "472 1.6960821636047285e-10\n",
            "473 1.647050135167305e-10\n",
            "474 1.5450632440128231e-10\n",
            "475 1.4764633959885032e-10\n",
            "476 1.4167439443824037e-10\n",
            "477 1.3830457612495906e-10\n",
            "478 1.3535172982415133e-10\n",
            "479 1.290908491213827e-10\n",
            "480 1.2329101628516526e-10\n",
            "481 1.2098358426193556e-10\n",
            "482 1.171244351505507e-10\n",
            "483 1.1454249354558854e-10\n",
            "484 1.0943999179113817e-10\n",
            "485 1.0468119426843003e-10\n",
            "486 1.013727921050922e-10\n",
            "487 9.909851411693538e-11\n",
            "488 9.967727337967247e-11\n",
            "489 9.686049878832037e-11\n",
            "490 9.358283592497685e-11\n",
            "491 9.148105190037725e-11\n",
            "492 8.991159899940371e-11\n",
            "493 8.712112281594742e-11\n",
            "494 8.479161817120939e-11\n",
            "495 8.357443209705551e-11\n",
            "496 8.282865365805137e-11\n",
            "497 8.168987014611773e-11\n",
            "498 8.139980356425269e-11\n",
            "499 8.042600613267226e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmye5H7OEymw",
        "colab_type": "text"
      },
      "source": [
        "## Summary\n",
        "\n",
        "–ù–∞ —ç—Ç–æ–º —É—Ä–æ–∫–µ –º—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å —Å —Ç—Ä–µ–º—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏ –¥–ª—è deep-learning:\n",
        " - TensorFlow - —É–∑–Ω–∞–ª–∏ –ø–æ—Ä—è–¥–æ–∫ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º, —É–∑–Ω–∞–ª–∏ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö Variable –∏ placeholder;\n",
        " - Keras (–∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Å–æ–≤—Å–µ–º —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∞ —Å–∫–æ—Ä–µ–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å) - –Ω–∞–ø–∏—Å–∞–ª–∏ –≤ –Ω–µ–º –ø—Ä–æ—Å—Ç—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å;\n",
        " - PyTorch - –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –Ω–∞–ø–∏—Å–∞–ª–∏ –ø—Ä–æ—Å—Ç—É—é –¥–≤—É—Å–ª–æ–π–Ω—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∏ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏, –∫–∞–∫ –µ–µ –æ–±—É—á–∞—Ç—å.\n",
        "\n",
        "–ü–æ–º–∏–º–æ —ç—Ç–æ–≥–æ, –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ –∑–∞–¥–∞—á—É –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –∞ –∏–º–µ–Ω–Ω–æ:\n",
        " - —É–∑–Ω–∞–ª–∏, —á—Ç–æ —Ç–∞–∫–æ–µ —Ñ—É–Ω–∫—Ü–∏—è Softmax;\n",
        " - —É–∑–Ω–∞–ª–∏, —á—Ç–æ —Ç–∞–∫–æ–µ one-hot encoding –∏ –∫–∞–∫ –µ–≥–æ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å –Ω–∞ tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ixtWxreEFXZ",
        "colab_type": "code",
        "outputId": "f52df96b-4191-41f0-9372-123779d2c2e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 23 08:14:08 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    30W /  70W |    293MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj7dg8BDjI4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}